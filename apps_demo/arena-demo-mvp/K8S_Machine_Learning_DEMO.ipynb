{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This demo shows:\n",
    "    - how to train machine learning model in k8s\n",
    "    - how to serve machine learning model in k8s\n",
    "    - how to provision machine learning environment in k8s\n",
    "    \n",
    "#### Useful links:\n",
    "1. ACK = Alibaba Container Service for Kubernetes : https://www.alibabacloud.com/product/kubernetes\n",
    "2. arena repo: https://github.com/kubeflow/arena\n",
    "3. arena example: https://github.com/jianhuashao/AliCloud_Demo_Container_Kubernetes/tree/master/arena\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 1: create a managed k8s GPU cluster in ACK\n",
    "\n",
    "1. assume a k8s GPU cluster has been created in ACK\n",
    "2. more details on how to create a k8s cluster in ack: https://www.alibabacloud.com/help/doc-detail/85903.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### lists nodes in k8s cluster\n",
      "NAME                        STATUS   ROLES    AGE   VERSION\n",
      "cn-shanghai.192.168.0.172   Ready    <none>   59m   v1.12.6-aliyun.1\n",
      "cn-shanghai.192.168.0.173   Ready    <none>   59m   v1.12.6-aliyun.1\n",
      "cn-shanghai.192.168.0.174   Ready    <none>   58m   v1.12.6-aliyun.1\n",
      "\n",
      "#### lists nodes utilisation\n",
      "NAME                        CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%   \n",
      "cn-shanghai.192.168.0.172   119m         0%     2632Mi          4%        \n",
      "cn-shanghai.192.168.0.173   151m         3%     3345Mi          11%       \n",
      "cn-shanghai.192.168.0.174   124m         3%     2590Mi          8%        \n",
      "CPU times: user 3.77 ms, sys: 5.34 ms, total: 9.11 ms\n",
      "Wall time: 13.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%bash\n",
    "\n",
    "echo -e\n",
    "echo -e \"#### lists nodes in k8s cluster\"\n",
    "kubectl get nodes\n",
    "\n",
    "echo -e\n",
    "echo -e \"#### lists nodes utilisation\"\n",
    "kubectl top nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# get node description\n",
      "Name:               cn-shanghai.192.168.0.174\n",
      "Roles:              <none>\n",
      "Labels:             aliyun.accelerator/nvidia_count=1\n",
      "                    aliyun.accelerator/nvidia_mem=12215MiB\n",
      "                    aliyun.accelerator/nvidia_name=Tesla-M40\n",
      "                    beta.kubernetes.io/arch=amd64\n",
      "                    beta.kubernetes.io/instance-type=ecs.gn4-c4g1.xlarge\n",
      "                    beta.kubernetes.io/os=linux\n",
      "                    failure-domain.beta.kubernetes.io/region=cn-shanghai\n",
      "                    failure-domain.beta.kubernetes.io/zone=cn-shanghai-b\n",
      "                    kubernetes.io/hostname=cn-shanghai.192.168.0.174\n",
      "Annotations:        flannel.alpha.coreos.com/backend-data: null\n",
      "                    flannel.alpha.coreos.com/backend-type: \n",
      "                    flannel.alpha.coreos.com/kube-subnet-manager: true\n",
      "                    flannel.alpha.coreos.com/public-ip: 192.168.0.174\n",
      "                    kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n",
      "                    node.alpha.kubernetes.io/ttl: 0\n",
      "CreationTimestamp:  Tue, 13 Aug 2019 15:57:58 +0100\n",
      "Taints:             <none>\n",
      "Unschedulable:      false\n",
      "Conditions:\n",
      "  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n",
      "  ----                 ------  -----------------                 ------------------                ------                       -------\n",
      "  NetworkUnavailable   False   Tue, 13 Aug 2019 16:56:15 +0100   Tue, 13 Aug 2019 16:56:15 +0100   RouteCreated                 RouteController created a route\n",
      "  OutOfDisk            False   Tue, 13 Aug 2019 16:56:34 +0100   Tue, 13 Aug 2019 15:57:58 +0100   KubeletHasSufficientDisk     kubelet has sufficient disk space available\n",
      "  MemoryPressure       False   Tue, 13 Aug 2019 16:56:34 +0100   Tue, 13 Aug 2019 15:57:58 +0100   KubeletHasSufficientMemory   kubelet has sufficient memory available\n",
      "  DiskPressure         False   Tue, 13 Aug 2019 16:56:34 +0100   Tue, 13 Aug 2019 15:57:58 +0100   KubeletHasNoDiskPressure     kubelet has no disk pressure\n",
      "  PIDPressure          False   Tue, 13 Aug 2019 16:56:34 +0100   Tue, 13 Aug 2019 15:57:58 +0100   KubeletHasSufficientPID      kubelet has sufficient PID available\n",
      "  Ready                True    Tue, 13 Aug 2019 16:56:34 +0100   Tue, 13 Aug 2019 15:59:59 +0100   KubeletReady                 kubelet is posting ready status\n",
      "Addresses:\n",
      "  InternalIP:  192.168.0.174\n",
      "Capacity:\n",
      " cpu:                4\n",
      " ephemeral-storage:  123722716Ki\n",
      " hugepages-1Gi:      0\n",
      " hugepages-2Mi:      0\n",
      " memory:             30716072Ki\n",
      " nvidia.com/gpu:     1\n",
      " pods:               110\n",
      "Allocatable:\n",
      " cpu:                4\n",
      " ephemeral-storage:  114022854877\n",
      " hugepages-1Gi:      0\n",
      " hugepages-2Mi:      0\n",
      " memory:             29692072Ki\n",
      " nvidia.com/gpu:     1\n",
      " pods:               110\n",
      "System Info:\n",
      " Machine ID:                 20190619144105153505835812255700\n",
      " System UUID:                E327AF55-847F-4063-B2E0-DBA6D4A1F5EC\n",
      " Boot ID:                    8af98443-d055-4eb2-b457-465779f96a24\n",
      " Kernel Version:             3.10.0-957.21.3.el7.x86_64\n",
      " OS Image:                   CentOS Linux 7 (Core)\n",
      " Operating System:           linux\n",
      " Architecture:               amd64\n",
      " Container Runtime Version:  docker://18.9.2\n",
      " Kubelet Version:            v1.12.6-aliyun.1\n",
      " Kube-Proxy Version:         v1.12.6-aliyun.1\n",
      "PodCIDR:                     172.20.1.0/25\n",
      "ProviderID:                  cn-shanghai.i-uf61s3dutuh653o131f4\n",
      "Non-terminated Pods:         (7 in total)\n",
      "  Namespace                  Name                                                CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n",
      "  ---------                  ----                                                ------------  ----------  ---------------  -------------  ---\n",
      "  kube-system                alicloud-application-controller-5c66955fc9-fll2b    0 (0%)        0 (0%)      0 (0%)           0 (0%)         56m\n",
      "  kube-system                alicloud-monitor-controller-64cf767748-9br82        100m (2%)     0 (0%)      200Mi (0%)       0 (0%)         56m\n",
      "  kube-system                flexvolume-78hgj                                    100m (2%)     0 (0%)      200Mi (0%)       1000Mi (3%)    53m\n",
      "  kube-system                kube-flannel-ds-4phbh                               0 (0%)        0 (0%)      0 (0%)           0 (0%)         56m\n",
      "  kube-system                kube-proxy-worker-4v8ft                             0 (0%)        0 (0%)      0 (0%)           0 (0%)         56m\n",
      "  kube-system                logtail-ds-fm64t                                    100m (2%)     0 (0%)      256Mi (0%)       512Mi (1%)     53m\n",
      "  kube-system                nvidia-device-plugin-cn-shanghai.192.168.0.174      1 (25%)       1 (25%)     300Mi (1%)       300Mi (1%)     58m\n",
      "Allocated resources:\n",
      "  (Total limits may be over 100 percent, i.e., overcommitted.)\n",
      "  Resource           Requests     Limits\n",
      "  --------           --------     ------\n",
      "  cpu                1300m (32%)  1 (25%)\n",
      "  memory             956Mi (3%)   1812Mi (6%)\n",
      "  ephemeral-storage  0 (0%)       0 (0%)\n",
      "  nvidia.com/gpu     0            0\n",
      "Events:\n",
      "  Type    Reason                   Age   From                                   Message\n",
      "  ----    ------                   ----  ----                                   -------\n",
      "  Normal  Starting                 58m   kubelet, cn-shanghai.192.168.0.174     Starting kubelet.\n",
      "  Normal  NodeHasSufficientDisk    58m   kubelet, cn-shanghai.192.168.0.174     Node cn-shanghai.192.168.0.174 status is now: NodeHasSufficientDisk\n",
      "  Normal  NodeHasSufficientMemory  58m   kubelet, cn-shanghai.192.168.0.174     Node cn-shanghai.192.168.0.174 status is now: NodeHasSufficientMemory\n",
      "  Normal  NodeHasNoDiskPressure    58m   kubelet, cn-shanghai.192.168.0.174     Node cn-shanghai.192.168.0.174 status is now: NodeHasNoDiskPressure\n",
      "  Normal  NodeHasSufficientPID     58m   kubelet, cn-shanghai.192.168.0.174     Node cn-shanghai.192.168.0.174 status is now: NodeHasSufficientPID\n",
      "  Normal  NodeAllocatableEnforced  58m   kubelet, cn-shanghai.192.168.0.174     Updated Node Allocatable limit across pods\n",
      "  Normal  NodeHasSufficientDisk    58m   kubelet, cn-shanghai.192.168.0.174     Node cn-shanghai.192.168.0.174 status is now: NodeHasSufficientDisk\n",
      "  Normal  Starting                 58m   kubelet, cn-shanghai.192.168.0.174     Starting kubelet.\n",
      "  Normal  NodeHasSufficientMemory  58m   kubelet, cn-shanghai.192.168.0.174     Node cn-shanghai.192.168.0.174 status is now: NodeHasSufficientMemory\n",
      "  Normal  NodeHasNoDiskPressure    58m   kubelet, cn-shanghai.192.168.0.174     Node cn-shanghai.192.168.0.174 status is now: NodeHasNoDiskPressure\n",
      "  Normal  NodeHasSufficientPID     58m   kubelet, cn-shanghai.192.168.0.174     Node cn-shanghai.192.168.0.174 status is now: NodeHasSufficientPID\n",
      "  Normal  NodeAllocatableEnforced  58m   kubelet, cn-shanghai.192.168.0.174     Updated Node Allocatable limit across pods\n",
      "  Normal  Starting                 56m   kube-proxy, cn-shanghai.192.168.0.174  Starting kube-proxy.\n",
      "  Normal  NodeReady                56m   kubelet, cn-shanghai.192.168.0.174     Node cn-shanghai.192.168.0.174 status is now: NodeReady\n",
      "CPU times: user 3.65 ms, sys: 5.82 ms, total: 9.47 ms\n",
      "Wall time: 5.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%bash\n",
    "\n",
    "echo \"# get node description\"\n",
    "#kubectl get nodes | tail -1 | sed 's/ .*//' | \n",
    "kubectl describe node/cn-shanghai.192.168.0.174"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "namespace/ml created\n",
      "CPU times: user 3.31 ms, sys: 5.66 ms, total: 8.97 ms\n",
      "Wall time: 2.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%bash\n",
    "\n",
    "kubectl create namespace ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No resources found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.25 ms, sys: 5.08 ms, total: 8.33 ms\n",
      "Wall time: 8.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%bash\n",
    "\n",
    "kubectl get all --namespace ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%bash\n",
    "\n",
    "## only run this to delete all resoruce created with this demo\n",
    "\n",
    "# kubectl delete --all pods --namespace ml\n",
    "# kubectl delete --all services --namespace ml\n",
    "# kubectl delete --all serviceaccount --namespace ml\n",
    "# kubectl delete --all rs --namespace ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arena: v0.3.0+32118f3\n",
      "  BuildDate: 2019-08-13T13:52:53Z\n",
      "  GitCommit: 32118f387ecfb1d039b997f0bce9bfbd8a4e8ff7\n",
      "  GitTreeState: clean\n",
      "  GoVersion: go1.12.7\n",
      "  Compiler: gc\n",
      "  Platform: darwin/amd64\n",
      "CPU times: user 3.21 ms, sys: 5.1 ms, total: 8.31 ms\n",
      "Wall time: 659 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%bash\n",
    "\n",
    "## check if arena is installed and get version if it is installed\n",
    "arena version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%bash\n",
    "\n",
    "## install arena if it not installed\n",
    "## pre-require golang \n",
    "\n",
    "echo -e \"#### gopath: \" $(go env GOPATH)\n",
    "\n",
    "rm -r $(go env GOPATH)/src/github.com/kubeflow/arena || true\n",
    "\n",
    "mkdir -p $(go env GOPATH)/src/github.com/kubeflow\n",
    "cd $(go env GOPATH)/src/github.com/kubeflow\n",
    "git clone https://github.com/kubeflow/arena.git\n",
    "\n",
    "cd $(go env GOPATH)/src/github.com/kubeflow/arena\n",
    "make\n",
    "cd $(go env GOPATH)/src/github.com/kubeflow\n",
    "ls -lha ./arena/bin\n",
    "\n",
    "cp $(go env GOPATH)/src/github.com/kubeflow/arena/bin/arena /usr/local/bin/\n",
    "ls -lha /usr/local/bin/arena\n",
    "\n",
    "## check which arena has been installed\n",
    "echo -e \"\\n#### check which arena \"\n",
    "which arena"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 2: configure k8s environemnt\n",
    "\n",
    "    - instakk kubectl \n",
    "    - install arena_cli\n",
    "    - install crd: tf\n",
    "    - install operator: ps, mpi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### install TFJob controller\n",
      "namespace/arena-system created\n",
      "serviceaccount/jobmon created\n",
      "clusterrolebinding.rbac.authorization.k8s.io/jobmon created\n",
      "customresourcedefinition.apiextensions.k8s.io/tfjobs.kubeflow.org created\n",
      "serviceaccount/tf-job-dashboard created\n",
      "serviceaccount/tf-job-operator created\n",
      "clusterrole.rbac.authorization.k8s.io/tf-job-dashboard created\n",
      "clusterrole.rbac.authorization.k8s.io/tf-job-operator created\n",
      "clusterrolebinding.rbac.authorization.k8s.io/tf-job-dashboard created\n",
      "clusterrolebinding.rbac.authorization.k8s.io/tf-job-operator created\n",
      "configmap/tf-job-operator-config created\n",
      "service/tf-job-dashboard created\n",
      "service/tf-job-operator created\n",
      "deployment.extensions/tf-job-dashboard created\n",
      "deployment.extensions/tf-job-operator created\n",
      "\n",
      "#### install arena Dashboard\n",
      "serviceaccount/dashboard created\n",
      "clusterrolebinding.rbac.authorization.k8s.io/dashboard-extended created\n",
      "rolebinding.rbac.authorization.k8s.io/dashboard-default created\n",
      "deployment.extensions/kubernetes-dashboard created\n",
      "service/kubernetes-dashboard created\n",
      "\n",
      "#### install MPIJob controller\n",
      "customresourcedefinition.apiextensions.k8s.io/mpijobs.kubeflow.org created\n",
      "clusterrole.rbac.authorization.k8s.io/mpi-operator created\n",
      "serviceaccount/mpi-operator created\n",
      "clusterrolebinding.rbac.authorization.k8s.io/mpi-operator created\n",
      "deployment.apps/mpi-operator created\n",
      "CPU times: user 6.9 ms, sys: 7.38 ms, total: 14.3 ms\n",
      "Wall time: 38.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%bash\n",
    "\n",
    "## you do not need to pass namesapce in, as they have been hard-coding into the yaml file bellow. \n",
    "\n",
    "echo -e \"\\n#### install TFJob controller\"\n",
    "kubectl apply -f ./arena/kubernetes-artifacts/jobmon/jobmon-role.yaml\n",
    "kubectl apply -f ./arena/kubernetes-artifacts/tf-operator/tf-crd.yaml\n",
    "kubectl apply -f ./arena/kubernetes-artifacts/tf-operator/tf-operator.yaml\n",
    "\n",
    "echo -e \"\\n#### install arena Dashboard\"\n",
    "kubectl apply -f ./arena/kubernetes-artifacts/dashboard/dashboard.yaml\n",
    "\n",
    "echo -e \"\\n#### install MPIJob controller\"\n",
    "kubectl apply -f arena/kubernetes-artifacts/mpi-operator/mpi-operator.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 3: model training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## to train distributed TensorFlow model in PS mode\n",
    "\n",
    "```\n",
    "Submit TFJob as training job.\n",
    "\n",
    "Usage:\n",
    "  arena submit tfjob flags\n",
    "\n",
    "Aliases:\n",
    "  tfjob, tf\n",
    "\n",
    "Flags:\n",
    "  -a, --annotation stringArray           the annotations\n",
    "      --chief                            enable chief, which is required for estimator.\n",
    "      --chief-cpu string                 the cpu resource to use for the Chief, like 1 for 1 core.\n",
    "      --chief-memory string              the memory resource to use for the Chief, like 1Gi.\n",
    "      --chief-port int                   the port of the chief.\n",
    "      --chief-selector stringArray       assigning jobs with \"Chief\" role to some k8s particular nodes(this option would cover --selector), usage: \"--chief-selector=key=value\"\n",
    "      --clean-task-policy string         How to clean tasks after Training is done, only support Running, None. (default \"Running\")\n",
    "  -d, --data stringArray                 specify the datasource to mount to the job, like <name_of_datasource>:<mount_point_on_job>\n",
    "      --data-dir stringArray             the data dir. If you specify /data, it means mounting hostpath /data into container path /data\n",
    "  -e, --env stringArray                  the environment variables\n",
    "      --evaluator                        enable evaluator, which is optional for estimator.\n",
    "      --evaluator-cpu string             the cpu resource to use for the evaluator, like 1 for 1 core.\n",
    "      --evaluator-memory string          the memory resource to use for the evaluator, like 1Gi.\n",
    "      --evaluator-selector stringArray   assigning jobs with \"Evaluator\" role to some k8s particular nodes(this option would cover --selector), usage: \"--evaluator-selector=key=value\"\n",
    "      --gpus int                         the GPU count of each worker to run the training.\n",
    "  -h, --help                             help for tfjob\n",
    "      --image string                     the docker image name of training job\n",
    "      --logdir string                    the training logs dir, default is /training_logs (default \"/training_logs\")\n",
    "      --name string                      override name\n",
    "  -p, --priority string                  priority class name\n",
    "      --ps int                           the number of the parameter servers.\n",
    "      --ps-cpu string                    the cpu resource to use for the parameter servers, like 1 for 1 core.\n",
    "      --ps-image string                  the docker image for tensorflow workers\n",
    "      --ps-memory string                 the memory resource to use for the parameter servers, like 1Gi.\n",
    "      --ps-port int                      the port of the parameter server.\n",
    "      --ps-selector stringArray          assigning jobs with \"PS\" role to some k8s particular nodes(this option would cover --selector), usage: \"--ps-selector=key=value\"\n",
    "      --rdma                             enable RDMA\n",
    "      --retry int                        retry times.\n",
    "      --selector stringArray             assigning jobs to some k8s particular nodes, usage: \"--selector=key=value\" or \"--selector key=value\"\n",
    "      --sync-image string                the docker image of syncImage\n",
    "      --sync-mode string                 syncMode: support rsync, hdfs, git\n",
    "      --sync-source string               sync-source: for rsync, it's like 10.88.29.56::backup/data/logoRecoTrain.zip; for git, it's like https://github.com/kubeflow/tf-operator.git\n",
    "      --tensorboard                      enable tensorboard\n",
    "      --tensorboard-image string         the docker image for tensorboard (default \"registry.cn-zhangjiakou.aliyuncs.com/tensorflow-samples/tensorflow:1.12.0-devel\")\n",
    "      --toleration stringArray           tolerate some k8s nodes with taints,usage: \"--toleration taint-key\" or \"--toleration all\"\n",
    "      --worker-cpu string                the cpu resource to use for the worker, like 1 for 1 core.\n",
    "      --worker-image string              the docker image for tensorflow workers\n",
    "      --worker-memory string             the memory resource to use for the worker, like 1Gi.\n",
    "      --worker-port int                  the port of the worker.\n",
    "      --worker-selector stringArray      assigning jobs with \"Worker\" role to some k8s particular nodes(this option would cover --selector), usage: \"--worker-selector=key=value\"\n",
    "      --workers int                      the worker number to run the distributed training. (default 1)\n",
    "      --working-dir string               working directory to extract the code. If using syncMode, the $workingDir/code contains the code (default \"/root\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configmap/tf-dist-git-tfjob created\n",
      "configmap/tf-dist-git-tfjob labeled\n",
      "service/tf-dist-git-tensorboard created\n",
      "deployment.extensions/tf-dist-git-tensorboard created\n",
      "tfjob.kubeflow.org/tf-dist-git created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "time=\"2019-08-13T16:58:55+01:00\" level=info msg=\"The Job tf-dist-git has been submitted successfully\"\n",
      "time=\"2019-08-13T16:58:55+01:00\" level=info msg=\"You can run `arena get tf-dist-git --type tfjob` to check the job status\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.21 ms, sys: 5.84 ms, total: 10.1 ms\n",
      "Wall time: 24.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%bash\n",
    "\n",
    "# The following command is an example. In this example, \n",
    "# it defines 2 workers and 1 PS, and each worker has 1 GPU. \n",
    "# The source code of worker and PS are located in git, and the tensorboard are enabled.\n",
    "\n",
    "arena submit tf \\\n",
    "    --name=tf-dist-git \\\n",
    "    --gpus=1 \\\n",
    "    --workers=2 \\\n",
    "    --worker-image=tensorflow/tensorflow:1.5.0-devel-gpu \\\n",
    "    --sync-mode=git \\\n",
    "    --sync-source=https://github.com/cheyang/tensorflow-sample-code.git \\\n",
    "    --ps=1 \\\n",
    "    --ps-image=tensorflow/tensorflow:1.5.0-devel \\\n",
    "    --tensorboard \\\n",
    "    \"python code/tensorflow-sample-code/tfjob/docker/v1alpha2/distributed-mnist/main.py --log_dir=/training_logs --data_dir=code/tensorflow-sample-code/data\" \\\n",
    "    --namespace ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train distributed TensorFlow model in MPI mode\n",
    "\n",
    "```\n",
    "Submit MPIjob as training job.\n",
    "\n",
    "Usage:\n",
    "  arena submit mpijob [flags]\n",
    "\n",
    "Aliases:\n",
    "  mpijob, mpi, mj\n",
    "\n",
    "Flags:\n",
    "  -a, --annotation stringArray     the annotations\n",
    "      --cpu string                 the cpu resource to use for the training, like 1 for 1 core.\n",
    "  -d, --data stringArray           specify the datasource to mount to the job, like <name_of_datasource>:<mount_point_on_job>\n",
    "      --data-dir stringArray       the data dir. If you specify /data, it means mounting hostpath /data into container path /data\n",
    "  -e, --env stringArray            the environment variables\n",
    "      --gpus int                   the GPU count of each worker to run the training.\n",
    "  -h, --help                       help for mpijob\n",
    "      --image string               the docker image name of training job\n",
    "      --logdir string              the training logs dir, default is /training_logs (default \"/training_logs\")\n",
    "      --memory string              the memory resource to use for the training, like 1Gi.\n",
    "      --name string                override name\n",
    "  -p, --priority string            priority class name\n",
    "      --rdma                       enable RDMA\n",
    "      --retry int                  retry times.\n",
    "      --selector stringArray       assigning jobs to some k8s particular nodes, usage: \"--selector=key=value\" or \"--selector key=value\"\n",
    "      --sync-image string          the docker image of syncImage\n",
    "      --sync-mode string           syncMode: support rsync, hdfs, git\n",
    "      --sync-source string         sync-source: for rsync, it's like 10.88.29.56::backup/data/logoRecoTrain.zip; for git, it's like https://github.com/kubeflow/tf-operator.git\n",
    "      --tensorboard                enable tensorboard\n",
    "      --tensorboard-image string   the docker image for tensorboard (default \"registry.cn-zhangjiakou.aliyuncs.com/tensorflow-samples/tensorflow:1.12.0-devel\")\n",
    "      --toleration stringArray     tolerate some k8s nodes with taints,usage: \"--toleration taint-key\" or \"--toleration all\"\n",
    "      --workers int                the worker number to run the distributed training. (default 1)\n",
    "      --working-dir string         working directory to extract the code. If using syncMode, the $workingDir/code contains the code (default \"/root\")\n",
    "\n",
    "Global Flags:\n",
    "      --arena-namespace string   The namespace of arena system service, like tf-operator (default \"arena-system\")\n",
    "      --config string            Path to a kube config. Only required if out-of-cluster\n",
    "      --loglevel string          Set the logging level. One of: debug|info|warn|error (default \"info\")\n",
    "  -n, --namespace string         the namespace of the job (default \"default\")\n",
    "      --pprof                    enable cpu profile\n",
    "      --trace                    enable trace\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configmap/mpi-dist-mpijob created\n",
      "configmap/mpi-dist-mpijob labeled\n",
      "service/mpi-dist-tensorboard created\n",
      "deployment.extensions/mpi-dist-tensorboard created\n",
      "mpijob.kubeflow.org/mpi-dist created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "time=\"2019-08-13T16:59:42+01:00\" level=info msg=\"The Job mpi-dist has been submitted successfully\"\n",
      "time=\"2019-08-13T16:59:42+01:00\" level=info msg=\"You can run `arena get mpi-dist --type mpijob` to check the job status\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.81 ms, sys: 5.49 ms, total: 9.29 ms\n",
      "Wall time: 22.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%bash\n",
    "\n",
    "# The following command is an example. In this example, \n",
    "# it defines 2 workers and 1 PS, and each worker has 1 GPU. \n",
    "# The source code of worker and PS are located in git, and the tensorboard are enabled.\n",
    "\n",
    "arena submit mpi --name=mpi-dist \\\n",
    "    --gpus=1 \\\n",
    "    --workers=2 \\\n",
    "    --image=uber/horovod:0.13.11-tf1.10.0-torch0.4.0-py3.5 \\\n",
    "    --env=GIT_SYNC_BRANCH=cnn_tf_v1.9_compatible \\\n",
    "    --sync-mode=git \\\n",
    "    --sync-source=https://github.com/tensorflow/benchmarks.git \\\n",
    "    --tensorboard \\\n",
    "    \"mpirun python code/benchmarks/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py --model resnet101 --batch_size 64 --variable_update horovod --train_dir=/training_logs --summary_verbosity=3 --save_summaries_steps=10\" \\\n",
    "    --namespace ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME         STATUS   TRAINER  AGE  NODE\n",
      "mpi-dist     PENDING  MPIJOB   2m   N/A\n",
      "tf-dist-git  PENDING  TFJOB    2m   N/A\n",
      "CPU times: user 3.77 ms, sys: 4.94 ms, total: 8.71 ms\n",
      "Wall time: 3.72 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%bash\n",
    "\n",
    "arena list --namespace ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME         GPU(Requests)  GPU(Allocated)  STATUS   TRAINER  AGE  NODE\n",
      "tf-dist-git  2              1               FAILED   tfjob    3m   N/A\n",
      "mpi-dist     2              2               PENDING  mpijob   2m   N/A\n",
      "\n",
      "\n",
      "Total Allocated GPUs of Training Job:\n",
      "3   \n",
      "\n",
      "Total Requested GPUs of Training Job:\n",
      "4   \n",
      "CPU times: user 3.23 ms, sys: 4.98 ms, total: 8.21 ms\n",
      "Wall time: 3.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%bash\n",
    "\n",
    "arena top job --namespace ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                       IPADDRESS      ROLE    STATUS  GPU(Total)  GPU(Allocated)\n",
      "cn-shanghai.192.168.0.172  192.168.0.172  <none>  ready   2           1\n",
      "cn-shanghai.192.168.0.173  192.168.0.173  <none>  ready   1           1\n",
      "cn-shanghai.192.168.0.174  192.168.0.174  <none>  ready   1           1\n",
      "-----------------------------------------------------------------------------------------\n",
      "Allocated/Total GPUs In Cluster:\n",
      "3/4 (75%)  \n",
      "CPU times: user 3.55 ms, sys: 5.92 ms, total: 9.47 ms\n",
      "Wall time: 5.96 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%bash\n",
    "\n",
    "arena top node --namespace ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%bash\n",
    "\n",
    "arena get tf-dist-git --namespace ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATUS: SUCCEEDED\n",
      "NAMESPACE: ml\n",
      "PRIORITY: N/A\n",
      "TRAINING DURATION: 11m\n",
      "\n",
      "NAME      STATUS     TRAINER  AGE  INSTANCE                 NODE\n",
      "mpi-dist  SUCCEEDED  MPIJOB   26m  mpi-dist-launcher-p45wz  192.168.0.173\n",
      "\n",
      "Your tensorboard will be available on:\n",
      "http://192.168.0.172:31325   \n",
      "CPU times: user 3.25 ms, sys: 5.3 ms, total: 8.55 ms\n",
      "Wall time: 5.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%bash\n",
    "\n",
    "arena get mpi-dist --namespace ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "%%bash\n",
    "\n",
    "arena logs tf-dist-git --namespace ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-13T16:07:57.80967213Z + POD_NAME=mpi-dist-worker-0\n",
      "2019-08-13T16:07:57.80972552Z + shift\n",
      "2019-08-13T16:07:57.809735101Z + /opt/kube/kubectl exec mpi-dist-worker-0 -- /bin/sh -c     PATH=/usr/local/bin:$PATH ; export PATH ; LD_LIBRARY_PATH=/usr/local/lib:$LD_LIBRARY_PATH ; export LD_LIBRARY_PATH ; DYLD_LIBRARY_PATH=/usr/local/lib:$DYLD_LIBRARY_PATH ; export DYLD_LIBRARY_PATH ;   /usr/local/bin/orted -mca ess \"env\" -mca ess_base_jobid \"1448214528\" -mca ess_base_vpid 1 -mca ess_base_num_procs \"3\" -mca orte_node_regex \"mpi-dist-launcher-p45wz,mpi-dist-worker-0,mpi-dist-worker-1@0(3)\" -mca orte_hnp_uri \"1448214528.0;tcp://172.20.0.139:36596\" -mca plm \"rsh\" -mca plm_rsh_agent \"/etc/mpi/kubexec.sh\" -mca orte_default_hostfile \"/etc/mpi/hostfile\" -mca pmix \"^s1,s2,cray,isolated\"\n",
      "2019-08-13T16:07:57.816403648Z + POD_NAME=mpi-dist-worker-1\n",
      "2019-08-13T16:07:57.816421307Z + shift\n",
      "2019-08-13T16:07:57.816563784Z + /opt/kube/kubectl exec mpi-dist-worker-1 -- /bin/sh -c     PATH=/usr/local/bin:$PATH ; export PATH ; LD_LIBRARY_PATH=/usr/local/lib:$LD_LIBRARY_PATH ; export LD_LIBRARY_PATH ; DYLD_LIBRARY_PATH=/usr/local/lib:$DYLD_LIBRARY_PATH ; export DYLD_LIBRARY_PATH ;   /usr/local/bin/orted -mca ess \"env\" -mca ess_base_jobid \"1448214528\" -mca ess_base_vpid 2 -mca ess_base_num_procs \"3\" -mca orte_node_regex \"mpi-dist-launcher-p45wz,mpi-dist-worker-0,mpi-dist-worker-1@0(3)\" -mca orte_hnp_uri \"1448214528.0;tcp://172.20.0.139:36596\" -mca plm \"rsh\" -mca plm_rsh_agent \"/etc/mpi/kubexec.sh\" -mca orte_default_hostfile \"/etc/mpi/hostfile\" -mca pmix \"^s1,s2,cray,isolated\"\n",
      "2019-08-13T16:08:02.173982747Z TensorFlow:  1.10\n",
      "2019-08-13T16:08:02.174036811Z Model:       resnet101\n",
      "2019-08-13T16:08:02.174044285Z Dataset:     imagenet (synthetic)\n",
      "2019-08-13T16:08:02.174049498Z Mode:        training\n",
      "2019-08-13T16:08:02.174054102Z SingleSess:  False\n",
      "2019-08-13T16:08:02.174059095Z Batch size:  128 global\n",
      "2019-08-13T16:08:02.174063856Z              64.0 per device\n",
      "2019-08-13T16:08:02.174067344Z Num batches: 100\n",
      "2019-08-13T16:08:02.174070333Z Num epochs:  0.01\n",
      "2019-08-13T16:08:02.174073281Z Devices:     ['horovod/gpu:0', 'horovod/gpu:1']\n",
      "2019-08-13T16:08:02.174076409Z Data format: NCHW\n",
      "2019-08-13T16:08:02.174079539Z Layout optimizer: False\n",
      "2019-08-13T16:08:02.174082407Z Optimizer:   sgd\n",
      "2019-08-13T16:08:02.174085231Z Variables:   horovod\n",
      "2019-08-13T16:08:02.174088143Z ==========\n",
      "2019-08-13T16:08:02.17409091Z TensorFlow:  1.10\n",
      "2019-08-13T16:08:02.174093823Z Model:       resnet101\n",
      "2019-08-13T16:08:02.174096812Z Dataset:     imagenet (synthetic)\n",
      "2019-08-13T16:08:02.174099623Z Mode:        training\n",
      "2019-08-13T16:08:02.174102414Z SingleSess:  False\n",
      "2019-08-13T16:08:02.174105217Z Batch size:  128 global\n",
      "2019-08-13T16:08:02.174108182Z              64.0 per device\n",
      "2019-08-13T16:08:02.174111003Z Num batches: 100\n",
      "2019-08-13T16:08:02.174113751Z Num epochs:  0.01\n",
      "2019-08-13T16:08:02.174116578Z Devices:     ['horovod/gpu:0', 'horovod/gpu:1']\n",
      "2019-08-13T16:08:02.174131142Z Data format: NCHW\n",
      "2019-08-13T16:08:02.174134432Z Layout optimizer: False\n",
      "2019-08-13T16:08:02.174137324Z Optimizer:   sgd\n",
      "2019-08-13T16:08:02.174140148Z Variables:   horovod\n",
      "2019-08-13T16:08:02.174143056Z ==========\n",
      "2019-08-13T16:08:02.180952366Z Generating model\n",
      "2019-08-13T16:08:02.181655141Z Generating model\n",
      "2019-08-13T16:08:12.305210996Z W0813 16:08:12.304583 139968852072192 tf_logging.py:125] From /root/code/rev-9815f5f84fd5e681bbffdfe3176272a5c4ff5621/scripts/tf_cnn_benchmarks/benchmark_cnn.py:1761: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n",
      "2019-08-13T16:08:12.305254309Z Instructions for updating:\n",
      "2019-08-13T16:08:12.305262089Z Please switch to tf.train.MonitoredTrainingSession\n",
      "2019-08-13T16:08:13.734670411Z 2019-08-13 16:08:13.733739: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-08-13T16:08:13.924013014Z 2019-08-13 16:08:13.923492: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-08-13T16:08:13.92501007Z 2019-08-13 16:08:13.924706: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: \n",
      "2019-08-13T16:08:13.92502815Z name: Tesla M40 major: 5 minor: 2 memoryClockRate(GHz): 0.9475\n",
      "2019-08-13T16:08:13.925034611Z pciBusID: 0000:00:07.0\n",
      "2019-08-13T16:08:13.925039432Z totalMemory: 11.93GiB freeMemory: 11.82GiB\n",
      "2019-08-13T16:08:13.925113594Z 2019-08-13 16:08:13.924753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0\n",
      "2019-08-13T16:08:14.408776836Z 2019-08-13 16:08:14.408279: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-08-13T16:08:14.408822651Z 2019-08-13 16:08:14.408364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 \n",
      "2019-08-13T16:08:14.408830779Z 2019-08-13 16:08:14.408377: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N \n",
      "2019-08-13T16:08:14.409062455Z 2019-08-13 16:08:14.408745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11424 MB memory) -> physical GPU (device: 0, name: Tesla M40, pci bus id: 0000:00:07.0, compute capability: 5.2)\n",
      "2019-08-13T16:08:15.351647422Z W0813 16:08:15.349891 140360314676992 tf_logging.py:125] From /root/code/rev-9815f5f84fd5e681bbffdfe3176272a5c4ff5621/scripts/tf_cnn_benchmarks/benchmark_cnn.py:1761: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n",
      "2019-08-13T16:08:15.351692176Z Instructions for updating:\n",
      "2019-08-13T16:08:15.35169901Z Please switch to tf.train.MonitoredTrainingSession\n",
      "2019-08-13T16:08:15.701474761Z I0813 16:08:15.700809 139968852072192 tf_logging.py:115] Running local_init_op.\n",
      "2019-08-13T16:08:16.127537777Z I0813 16:08:16.126872 139968852072192 tf_logging.py:115] Done running local_init_op.\n",
      "2019-08-13T16:08:16.649900882Z I0813 16:08:16.647966 139968852072192 tf_logging.py:115] Starting standard services.\n",
      "2019-08-13T16:08:16.649940918Z W0813 16:08:16.648312 139968852072192 tf_logging.py:125] Standard services need a 'logdir' passed to the SessionManager\n",
      "2019-08-13T16:08:16.649948122Z I0813 16:08:16.648494 139968852072192 tf_logging.py:115] Starting queue runners.\n",
      "2019-08-13T16:08:16.869420577Z 2019-08-13 16:08:16.867689: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-08-13T16:08:17.069736182Z 2019-08-13 16:08:17.068129: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-08-13T16:08:17.070767214Z 2019-08-13 16:08:17.069336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: \n",
      "2019-08-13T16:08:17.07078645Z name: Tesla M40 major: 5 minor: 2 memoryClockRate(GHz): 0.9475\n",
      "2019-08-13T16:08:17.070791255Z pciBusID: 0000:00:07.0\n",
      "2019-08-13T16:08:17.070794329Z totalMemory: 11.93GiB freeMemory: 11.82GiB\n",
      "2019-08-13T16:08:17.070797428Z 2019-08-13 16:08:17.069384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0\n",
      "2019-08-13T16:08:17.59988209Z 2019-08-13 16:08:17.598260: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-08-13T16:08:17.599923076Z 2019-08-13 16:08:17.598326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 \n",
      "2019-08-13T16:08:17.599928149Z 2019-08-13 16:08:17.598338: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N \n",
      "2019-08-13T16:08:17.600145207Z 2019-08-13 16:08:17.598794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11424 MB memory) -> physical GPU (device: 0, name: Tesla M40, pci bus id: 0000:00:07.0, compute capability: 5.2)\n",
      "2019-08-13T16:08:18.993907076Z I0813 16:08:18.992151 140360314676992 tf_logging.py:115] Running local_init_op.\n",
      "2019-08-13T16:08:19.478094157Z I0813 16:08:19.476304 140360314676992 tf_logging.py:115] Done running local_init_op.\n",
      "2019-08-13T16:08:24.828649276Z I0813 16:08:24.826805 140360314676992 tf_logging.py:115] Starting standard services.\n",
      "2019-08-13T16:08:24.925529294Z I0813 16:08:24.923782 140360314676992 tf_logging.py:115] Starting queue runners.\n",
      "2019-08-13T16:08:25.806606561Z I0813 16:08:25.804777 140357475825408 tf_logging.py:159] global_step/sec: 0\n",
      "2019-08-13T16:08:26.819245017Z Running warm up\n",
      "2019-08-13T16:08:26.873815176Z Running warm up\n",
      "2019-08-13T16:08:33.628618516Z \n",
      "2019-08-13T16:08:33.628665458Z mpi-dist-worker-0:8787:8881 [0] misc/ibvwrap.cu:61 WARN Failed to open libibverbs.so[.1]\n",
      "2019-08-13T16:08:33.628672313Z mpi-dist-worker-0:8787:8881 [0] INFO Using internal Network Socket\n",
      "2019-08-13T16:08:33.628695786Z mpi-dist-worker-0:8787:8881 [0] INFO Using NCCL Low-latency algorithm for sizes below 16384\n",
      "2019-08-13T16:08:33.628701386Z mpi-dist-worker-0:8787:8881 [0] INFO NET : Using interface eth0:172.20.1.4<0>\n",
      "2019-08-13T16:08:33.628706756Z mpi-dist-worker-0:8787:8881 [0] INFO NET/Socket : 1 interfaces found\n",
      "2019-08-13T16:08:33.628711582Z NCCL version 2.2.13+cuda9.0\n",
      "2019-08-13T16:08:33.633739211Z 2019-08-13 16:08:33.632240: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.54GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2019-08-13T16:08:33.640959237Z mpi-dist-worker-0:8787:8881 [0] INFO comm 0x7fa7b02eb540 rank 0 nranks 2\n",
      "2019-08-13T16:08:33.772751568Z 2019-08-13 16:08:33.771111: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.32GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2019-08-13T16:08:33.864568049Z \n",
      "2019-08-13T16:08:33.864592779Z mpi-dist-worker-1:11971:12072 [0] misc/ibvwrap.cu:61 WARN Failed to open libibverbs.so[.1]\n",
      "2019-08-13T16:08:33.864596969Z mpi-dist-worker-1:11971:12072 [0] INFO Using internal Network Socket\n",
      "2019-08-13T16:08:33.864600268Z mpi-dist-worker-1:11971:12072 [0] INFO Using NCCL Low-latency algorithm for sizes below 16384\n",
      "2019-08-13T16:08:33.875371845Z mpi-dist-worker-1:11971:12072 [0] INFO comm 0x7f4c8c325bb0 rank 1 nranks 2\n",
      "2019-08-13T16:08:33.875389628Z mpi-dist-worker-1:11971:12072 [0] INFO NET : Using interface eth0:172.20.0.138<0>\n",
      "2019-08-13T16:08:33.875396925Z mpi-dist-worker-1:11971:12072 [0] INFO NET/Socket : 1 interfaces found\n",
      "2019-08-13T16:08:33.877315336Z mpi-dist-worker-0:8787:8881 [0] INFO Using 256 threads\n",
      "2019-08-13T16:08:33.877601963Z mpi-dist-worker-0:8787:8881 [0] INFO Min Comp Cap 5\n",
      "2019-08-13T16:08:33.877614256Z mpi-dist-worker-0:8787:8881 [0] INFO NCCL_SINGLE_RING_THRESHOLD=131072\n",
      "2019-08-13T16:08:33.87973561Z mpi-dist-worker-0:8787:8881 [0] INFO Ring 00 :    0   1\n",
      "2019-08-13T16:08:33.886842658Z mpi-dist-worker-1:11971:12072 [0] INFO 0 -> 1 via NET/Socket/0\n",
      "2019-08-13T16:08:33.887801661Z mpi-dist-worker-0:8787:8881 [0] INFO 1 -> 0 via NET/Socket/0\n",
      "2019-08-13T16:08:33.904435426Z mpi-dist-worker-0:8787:8881 [0] INFO Launch mode Parallel\n",
      "2019-08-13T16:08:48.923268998Z Done warm up\n",
      "2019-08-13T16:08:48.923312804Z Step\tImg/sec\ttotal_loss\n",
      "2019-08-13T16:08:53.16352706Z Done warm up\n",
      "2019-08-13T16:08:53.170150401Z Step\tImg/sec\ttotal_loss\n",
      "2019-08-13T16:08:54.164844217Z 1\timages/sec: 12.2 +/- 0.0 (jitter = 0.0)\t8.945\n",
      "2019-08-13T16:08:54.165788613Z 1\timages/sec: 64.3 +/- 0.0 (jitter = 0.0)\t9.062\n",
      "2019-08-13T16:09:03.107366469Z 10\timages/sec: 45.1 +/- 5.0 (jitter = 0.7)\t9.118\n",
      "2019-08-13T16:09:07.350199862Z 10\timages/sec: 45.1 +/- 5.0 (jitter = 0.5)\t9.104\n",
      "2019-08-13T16:09:17.543693571Z 20\timages/sec: 44.7 +/- 3.5 (jitter = 1.7)\t8.955\n",
      "2019-08-13T16:09:21.701378432Z 20\timages/sec: 44.9 +/- 3.5 (jitter = 1.4)\t9.138\n",
      "2019-08-13T16:09:32.044784047Z 30\timages/sec: 44.5 +/- 2.8 (jitter = 1.7)\t9.189\n",
      "2019-08-13T16:09:35.962306848Z 30\timages/sec: 44.9 +/- 2.8 (jitter = 1.5)\t9.125\n",
      "2019-08-13T16:09:46.044414214Z 40\timages/sec: 44.8 +/- 2.4 (jitter = 1.7)\t9.153\n",
      "2019-08-13T16:09:50.167870685Z 40\timages/sec: 45.0 +/- 2.4 (jitter = 1.4)\t9.180\n",
      "2019-08-13T16:10:00.268193944Z 50\timages/sec: 44.9 +/- 2.2 (jitter = 1.4)\t9.030\n",
      "2019-08-13T16:10:04.390851552Z 50\timages/sec: 45.0 +/- 2.2 (jitter = 1.0)\t9.161\n",
      "2019-08-13T16:10:14.557867912Z 60\timages/sec: 44.8 +/- 2.0 (jitter = 1.1)\t9.044\n",
      "2019-08-13T16:10:18.648532333Z 60\timages/sec: 45.0 +/- 2.0 (jitter = 0.9)\t9.238\n",
      "2019-08-13T16:10:24.927618509Z I0813 16:10:24.925424 140357475825408 tf_logging.py:159] global_step/sec: 0.638008\n",
      "2019-08-13T16:10:28.707605247Z 70\timages/sec: 44.9 +/- 1.8 (jitter = 1.1)\t9.090\n",
      "2019-08-13T16:10:32.843024629Z 70\timages/sec: 45.0 +/- 1.8 (jitter = 0.8)\t9.028\n",
      "2019-08-13T16:10:43.152829594Z 80\timages/sec: 44.8 +/- 1.7 (jitter = 1.1)\t9.119\n",
      "2019-08-13T16:10:47.199217337Z 80\timages/sec: 45.0 +/- 1.7 (jitter = 0.8)\t9.194\n",
      "2019-08-13T16:10:57.499920711Z 90\timages/sec: 44.8 +/- 1.6 (jitter = 1.0)\t9.021\n",
      "2019-08-13T16:11:01.474745033Z 90\timages/sec: 44.9 +/- 1.6 (jitter = 0.8)\t8.924\n",
      "2019-08-13T16:11:11.778533405Z 100\timages/sec: 44.8 +/- 1.5 (jitter = 1.1)\t9.069\n",
      "2019-08-13T16:11:11.778579762Z ----------------------------------------------------------------\n",
      "2019-08-13T16:11:11.778586361Z total images/sec: 89.60\n",
      "2019-08-13T16:11:11.77859135Z ----------------------------------------------------------------\n",
      "2019-08-13T16:11:15.776697478Z 100\timages/sec: 44.9 +/- 1.5 (jitter = 0.9)\t8.999\n",
      "2019-08-13T16:11:15.79314706Z ----------------------------------------------------------------\n",
      "2019-08-13T16:11:15.799919178Z total images/sec: 89.75\n",
      "2019-08-13T16:11:15.799933925Z ----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.8 ms, sys: 5.97 ms, total: 9.76 ms\n",
      "Wall time: 6.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%bash\n",
    "\n",
    "arena logs mpi-dist --namespace ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 4: model serving\n",
    "\n",
    "```\n",
    "Submit tensorflow serving job to deploy and serve machine learning models.\n",
    "\n",
    "Usage:\n",
    "  arena serve tensorflow [flags]\n",
    "\n",
    "Aliases:\n",
    "  tensorflow, tf\n",
    "\n",
    "Flags:\n",
    "      --command string             the command will inject to container's command.\n",
    "      --cpu string                 the request cpu of each replica to run the serve.\n",
    "  -d, --data stringArray           specify the trained models datasource to mount for serving, like <name_of_datasource>:<mount_point_on_job>\n",
    "      --enable-istio               enable Istio for serving or not (disable Istio by default)\n",
    "  -e, --envs stringArray           the environment variables\n",
    "      --expose-service             expose service using Istio gateway for external access or not (not expose by default)\n",
    "      --gpumemory int              the limit GPU memory of each replica to run the serve.\n",
    "      --gpus int                   the limit GPU count of each replica to run the serve.\n",
    "  -h, --help                       help for tensorflow\n",
    "      --image string               the docker image name of serve job, and the default image is tensorflow/serving:latest (default \"tensorflow/serving:latest\")\n",
    "      --image-pull-policy string   the policy to pull the image, and the default policy is IfNotPresent (default \"IfNotPresent\")\n",
    "      --memory string              the request memory of each replica to run the serve.\n",
    "      --model-name string          the model name for serving\n",
    "      --model-path string          the model path for serving in the container\n",
    "      --modelConfigFile string     Corresponding with --model_config_file in tensorflow serving\n",
    "      --name string                the serving name\n",
    "      --port int                   the port of tensorflow gRPC listening port (default 8500)\n",
    "      --replicas int               the replicas number of the serve job. (default 1)\n",
    "      --restfulPort int            the port of tensorflow RESTful listening port (default 8501)\n",
    "      --version string             the serving version\n",
    "      --versionPolicy string       support latest, latest:N, specific:N, all\n",
    "\n",
    "Global Flags:\n",
    "      --arena-namespace string   The namespace of arena system service, like tf-operator (default \"arena-system\")\n",
    "      --config string            Path to a kube config. Only required if out-of-cluster\n",
    "      --loglevel string          Set the logging level. One of: debug|info|warn|error (default \"info\")\n",
    "  -n, --namespace string         the namespace of the job (default \"default\")\n",
    "      --pprof                    enable cpu profile\n",
    "      --trace                    enable trace\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configmap/mymnist-201908131729-tf-serving created\n",
      "configmap/mymnist-201908131729-tf-serving labeled\n",
      "configmap/mymnist-201908131729-tensorflow-serving-cm created\n",
      "service/mymnist-201908131729-tensorflow-serving created\n",
      "deployment.extensions/mymnist-201908131729-tensorflow-serving created\n",
      "CPU times: user 3.77 ms, sys: 5.78 ms, total: 9.55 ms\n",
      "Wall time: 19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%bash\n",
    "\n",
    "arena serve tf \\\n",
    "    --name=mymnist \\\n",
    "    --model-name=mnist \\\n",
    "    --image=tensorflow/serving:latest \\\n",
    "    --data=tfmodel:/tfmodel \\\n",
    "    --model-path=/tfmodel/mnist \\\n",
    "    --versionPolicy=specific:1 \\\n",
    "    --namespace ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME     TYPE        VERSION       DESIRED  AVAILABLE  ENDPOINT_ADDRESS  PORTS\n",
      "mymnist  TENSORFLOW  201908131800  1        1          172.21.11.198     serving:8500,http-serving:8501\n",
      "CPU times: user 3.19 ms, sys: 6.11 ms, total: 9.29 ms\n",
      "Wall time: 2.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%bash\n",
    "\n",
    "arena serve list --namespace ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use sshuttle for quick test\n",
    "# sshuttle -r root@47.103.139.226 172.0.0.0/8\n",
    "# sshuttle -r root@47.103.139.226 0.0.0.0/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "d7 = [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3294117748737335, 0.7254902124404907, 0.6235294342041016, 0.5921568870544434, 0.2352941334247589, 0.1411764770746231, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8705883026123047, 0.9960784912109375, 0.9960784912109375, 0.9960784912109375, 0.9960784912109375, 0.9450981020927429, 0.7764706611633301, 0.7764706611633301, 0.7764706611633301, 0.7764706611633301, 0.7764706611633301, 0.7764706611633301, 0.7764706611633301, 0.7764706611633301, 0.6666666865348816, 0.2039215862751007, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26274511218070984, 0.44705885648727417, 0.2823529541492462, 0.44705885648727417, 0.6392157077789307, 0.8901961445808411, 0.9960784912109375, 0.8823530077934265, 0.9960784912109375, 0.9960784912109375, 0.9960784912109375, 0.9803922176361084, 0.8980392813682556, 0.9960784912109375, 0.9960784912109375, 0.5490196347236633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06666667014360428, 0.25882354378700256, 0.05490196496248245, 0.26274511218070984, 0.26274511218070984, 0.26274511218070984, 0.23137256503105164, 0.08235294371843338, 0.9254902601242065, 0.9960784912109375, 0.41568630933761597, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32549020648002625, 0.9921569228172302, 0.8196079134941101, 0.07058823853731155, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08627451211214066, 0.9137255549430847, 1.0, 0.32549020648002625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5058823823928833, 0.9960784912109375, 0.9333333969116211, 0.1725490242242813, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23137256503105164, 0.9764706492424011, 0.9960784912109375, 0.24313727021217346, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5215686559677124, 0.9960784912109375, 0.7333333492279053, 0.019607843831181526, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03529411926865578, 0.803921639919281, 0.9725490808486938, 0.22745099663734436, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4941176772117615, 0.9960784912109375, 0.7137255072593689, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29411765933036804, 0.9843137860298157, 0.9411765336990356, 0.22352942824363708, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07450980693101883, 0.8666667342185974, 0.9960784912109375, 0.6509804129600525, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011764707043766975, 0.7960785031318665, 0.9960784912109375, 0.8588235974311829, 0.13725490868091583, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14901961386203766, 0.9960784912109375, 0.9960784912109375, 0.3019607961177826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12156863510608673, 0.8784314393997192, 0.9960784912109375, 0.45098042488098145, 0.003921568859368563, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5215686559677124, 0.9960784912109375, 0.9960784912109375, 0.2039215862751007, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2392157018184662, 0.9490196704864502, 0.9960784912109375, 0.9960784912109375, 0.2039215862751007, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4745098352432251, 0.9960784912109375, 0.9960784912109375, 0.8588235974311829, 0.1568627506494522, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4745098352432251, 0.9960784912109375, 0.8117647767066956, 0.07058823853731155, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n",
    "\n",
    "d = d7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### preview the image for testing\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAxUlEQVR4nGNgGDaAEUKFpD77sfTFHeyS9xQYGBg+X4UKPuk6w8DAwMDAAuGm6l/TMnSweCzLwPDntSTDozPIOhkYGBgYBA3PmDIw/Lh1XShnGi5nBP+9KIRLTuzl/2AokwlDMlv0/U1cGq1//rPDJcfQ+m83Ky45zrM/rHBqrPu3Daec9+8PlrjkhO/+W4ZLjvn0v9vKuCTV/v3zxSUn/+BfMSMuydZ//0xwydl+QpdEClsbHoa7X1AkWZA5F53f4TIWEwAAaRE8kJuHrgAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x114381490>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import ast\n",
    "import numpy as numpy\n",
    "import PIL.Image as pil\n",
    "\n",
    "testImage = (numpy.array(d, dtype='float')).reshape(28,28)\n",
    "img = pil.fromarray(numpy.uint8(testImage * 255) , 'L')\n",
    "print(\"#### preview the image for testing\")\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"predictions\": [[2.04608277e-05, 1.72721548e-09, 7.74099826e-05, 0.00364777725, 1.25222709e-06, 2.27522014e-05, 1.14668977e-08, 0.99597472, 3.68833389e-05, 0.000218785644]\n",
      "    ]\n",
      "}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "100  5916  100   185  100  5731    288   8933 --:--:-- --:--:-- --:--:--  8926\r",
      "100  5916  100   185  100  5731    288   8932 --:--:-- --:--:-- --:--:--  8926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.52 ms, sys: 6.38 ms, total: 9.9 ms\n",
      "Wall time: 671 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%bash\n",
    "\n",
    "# pass an image of 7\n",
    "\n",
    "curl \\\n",
    "    -X POST http://172.21.11.198:8501/v1/models/mnist:predict \\\n",
    "    -d '{\"signature_name\": \"predict_images\", \"instances\": [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3294117748737335, 0.7254902124404907, 0.6235294342041016, 0.5921568870544434, 0.2352941334247589, 0.1411764770746231, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8705883026123047, 0.9960784912109375, 0.9960784912109375, 0.9960784912109375, 0.9960784912109375, 0.9450981020927429, 0.7764706611633301, 0.7764706611633301, 0.7764706611633301, 0.7764706611633301, 0.7764706611633301, 0.7764706611633301, 0.7764706611633301, 0.7764706611633301, 0.6666666865348816, 0.2039215862751007, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26274511218070984, 0.44705885648727417, 0.2823529541492462, 0.44705885648727417, 0.6392157077789307, 0.8901961445808411, 0.9960784912109375, 0.8823530077934265, 0.9960784912109375, 0.9960784912109375, 0.9960784912109375, 0.9803922176361084, 0.8980392813682556, 0.9960784912109375, 0.9960784912109375, 0.5490196347236633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06666667014360428, 0.25882354378700256, 0.05490196496248245, 0.26274511218070984, 0.26274511218070984, 0.26274511218070984, 0.23137256503105164, 0.08235294371843338, 0.9254902601242065, 0.9960784912109375, 0.41568630933761597, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32549020648002625, 0.9921569228172302, 0.8196079134941101, 0.07058823853731155, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08627451211214066, 0.9137255549430847, 1.0, 0.32549020648002625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5058823823928833, 0.9960784912109375, 0.9333333969116211, 0.1725490242242813, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23137256503105164, 0.9764706492424011, 0.9960784912109375, 0.24313727021217346, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5215686559677124, 0.9960784912109375, 0.7333333492279053, 0.019607843831181526, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03529411926865578, 0.803921639919281, 0.9725490808486938, 0.22745099663734436, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4941176772117615, 0.9960784912109375, 0.7137255072593689, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29411765933036804, 0.9843137860298157, 0.9411765336990356, 0.22352942824363708, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07450980693101883, 0.8666667342185974, 0.9960784912109375, 0.6509804129600525, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011764707043766975, 0.7960785031318665, 0.9960784912109375, 0.8588235974311829, 0.13725490868091583, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14901961386203766, 0.9960784912109375, 0.9960784912109375, 0.3019607961177826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12156863510608673, 0.8784314393997192, 0.9960784912109375, 0.45098042488098145, 0.003921568859368563, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5215686559677124, 0.9960784912109375, 0.9960784912109375, 0.2039215862751007, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2392157018184662, 0.9490196704864502, 0.9960784912109375, 0.9960784912109375, 0.2039215862751007, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4745098352432251, 0.9960784912109375, 0.9960784912109375, 0.8588235974311829, 0.1568627506494522, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4745098352432251, 0.9960784912109375, 0.8117647767066956, 0.07058823853731155, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]}'\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%bash\n",
    "\n",
    "# arena serve delete mymnist --namespace ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 5: create a jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 176\n",
      "drwxr-xr-x   8 jhs  staff   256B 13 Aug 18:03 .\n",
      "drwxr-xr-x  12 jhs  staff   384B 13 Aug 17:17 ..\n",
      "-rw-r--r--@  1 jhs  staff   6.0K 12 Aug 20:07 .DS_Store\n",
      "drwxr-xr-x   3 jhs  staff    96B 12 Aug 22:55 .ipynb_checkpoints\n",
      "-rw-r--r--   1 jhs  staff    69K 13 Aug 18:03 K8S Machine Learning DEMO.ipynb\n",
      "drwxr-xr-x  35 jhs  staff   1.1K 12 Aug 20:04 arena\n",
      "-rw-r--r--   1 jhs  staff   1.0K 13 Aug 18:09 tls.crt\n",
      "-rw-r--r--   1 jhs  staff   1.7K 13 Aug 18:09 tls.key\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating a 2048 bit RSA private key\n",
      ".........+++\n",
      "........................+++\n",
      "writing new private key to 'tls.key'\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%bash \n",
    "\n",
    "# foo.bar.com can be replace to your own domain name\n",
    "domain=\"foo.bar.com\"\n",
    "openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout tls.key -out tls.crt -subj \"/CN=$domain/O=$domain\"\n",
    "ls -lha ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secret \"notebook-secret\" deleted\n",
      "secret/notebook-secret created\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%bash\n",
    "\n",
    "kubectl delete secret notebook-secret --namespace ml # delete it if exists\n",
    "\n",
    "kubectl create secret tls notebook-secret --key tls.key --cert tls.crt --namespace ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "serviceaccount/susan-notebook created\n",
      "clusterrole.rbac.authorization.k8s.io/susan-notebook created\n",
      "role.rbac.authorization.k8s.io/susan-notebook created\n",
      "clusterrolebinding.rbac.authorization.k8s.io/susan-notebook-cluster-role created\n",
      "rolebinding.rbac.authorization.k8s.io/susan-notebook-role created\n",
      "statefulset.apps/susan-notebook created\n",
      "service/susan-notebook created\n",
      "ingress.extensions/susan-notebook-ingress created\n",
      "Install successful\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%bash \n",
    "\n",
    "curl -s https://raw.githubusercontent.com/AliyunContainerService/ai-starter/master/scripts/install_notebook.sh | \\\n",
    "    bash -s -- \\\n",
    "    --notebook-name susan \\\n",
    "    --ingress --ingress-domain foo.bar.com --ingress-secret notebook-secret \\\n",
    "    --pvc-name tfmodel \\\n",
    "    --namespace ml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                      READY   STATUS              RESTARTS   AGE\n",
      "mpi-dist-launcher-p45wz                                   0/1     Completed           0          65m\n",
      "mpi-dist-tensorboard-6ddd7bb694-56hw5                     1/1     Running             0          73m\n",
      "mymnist-201908131800-tensorflow-serving-d99f9549d-tld66   1/1     Running             0          11m\n",
      "susan-notebook-0                                          0/1     ContainerCreating   0          67s\n",
      "tf-dist-git-ps-0                                          0/1     Init:Error          0          74m\n",
      "tf-dist-git-tensorboard-5fcd87f6fd-zv2g9                  1/1     Running             0          74m\n",
      "tf-dist-git-worker-0                                      0/1     Init:Error          0          74m\n",
      "tf-dist-git-worker-1                                      0/1     Init:Error          0          74m\n",
      "CPU times: user 3.35 ms, sys: 4.55 ms, total: 7.9 ms\n",
      "Wall time: 1.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%bash\n",
    "\n",
    "kubectl get pods --namespace ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook pod ip is 172.20.0.13\n",
      "Notebook access token is 2efa492bd6238cab4194c74649d5b364503b44a473e0ad5e\n",
      "Ingress of notebook ip is 106.15.155.80\n",
      "Ingress of notebook domain is foo.bar.com\n",
      "CPU times: user 3.48 ms, sys: 7.01 ms, total: 10.5 ms\n",
      "Wall time: 9.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%bash\n",
    "\n",
    "curl -s https://raw.githubusercontent.com/AliyunContainerService/ai-starter/master/scripts/print_notebook.sh | \\\n",
    "    bash -s -- --notebook-name susan --namespace ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "open http://172.20.0.13:8888"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 6: model saving and transfer\n",
    "\n",
    "to continue ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
